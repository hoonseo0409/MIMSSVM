import MLJBase
using LinearAlgebra: norm, I, pinv, eigen, tr, Diagonal, mul!, diagind, svd
using Flux: onehotbatch, onecold
using MLJ: levels, nrows
using CategoricalArrays: CategoricalArray
using CUDA
using TimerOutputs
using Infiltrator

mutable struct MIMSSVMClassifier <: MLJBase.Deterministic
    M_cut::Array{UnitRange{Int64},1} # How to "cut" X into multimodal data
    Î´::Float64
    Ï„_1::Float64 ## impact of group 1 norm.
    Ï„_2::Float64 ## impact of trace norm.
    C::Float64
    Î¼::Float64
    Ï::Float64
    maxiter::Int64
    tol::Float64
    use_CUDA::Bool
    exact::Bool
end

mutable struct mimmsvm_vars
    # Original vars
    X::Array{Float64, 2}
    X_cut::Array{UnitRange{Int64}, 1}
    Y::Array{Float64, 2}
    W::Array{Float64, 2}
    b::Array{Float64, 1}

    # Introduced vars
    E::Array{Float64, 2}
    Q::Array{Float64, 2}
    R::Array{Float64, 2}
    T::Array{Float64, 2}
    U::Array{Float64, 2}
    V::Array{Float64, 2}
    D_1s::Vector{Array{Float64, 2}}
    D_2::Array{Float64, 2}

    # Lagrangian Multipliers
    Î›::Array{Float64, 2}
    Î£::Array{Float64, 2}
    Î©::Array{Float64, 2}
    Î˜::Array{Float64, 2}
    Îž::Array{Float64, 2}
    Î“::Array{Float64, 2}

    # Auxilary vars
    Î¼::Float64
    YI::Array{Float64, 2}
    WmX::Array{Float64, 2}
    WyX::Array{Float64, 2}
    by::Array{Float64, 2}

    # Note: the residual arrays can also be used as temporary storage
    E_res::Array{Float64, 2}
    Q_res::Array{Float64, 2}
    R_res::Array{Float64, 2}
    T_res::Array{Float64, 2}
    U_res::Array{Float64, 2}
    V_res::Array{Float64, 2}

    # To speed up W update (https://math.stackexchange.com/questions/670649/efficient-diagonal-update-of-matrix-inverse)
    Ps::Array{Array{Float64, 2}}
    Ds::Array{Diagonal}
    Pâ»Â¹s::Array{Array{Float64, 2}}

    # Temporary arrays
    tmp1d::Array{Float64, 2} # A temporary 1 Ã— d Array
    tmpdd::Array{Float64, 2} # A temporary d Ã— d Array
    tmpdd2::Array{Float64, 2} # A second temporary d Ã— d Array
    tmpKd::Array{Float64, 2} # A temporary K Ã— d Array
    tmpKd2::Array{Float64, 2} # A second temporary K Ã— d Array
    tmpKNI::Array{Float64, 2} # A temporary K Ã— NI Array
    tmpKprime::Array{Array{Float64, 2}} # K temporary K Ã— NIprime Arrays

    # vars for inexact W update
    s::Array{Float64, 1}
    âˆ‡W::Array{Float64, 2}
    prime_sum::Array{Int64, 1}
    prime_cut::Array{UnitRange{Int64}, 1}
    Xáµ€prime::Array{Array{Float64, 2}}
    XXáµ€_KXXáµ€prime::Array{Array{Float64, 2}}

    # vars for dim
    K::Int
    G::Int
end

function mimmsvm_vars(; X, X_cut, Y, W, b, E, Q, R, T, U, V, D_1s, D_2, Î›, Î£, Î©, Î˜, Îž, Î“, Î¼, YI, WmX, WyX, by, E_res, Q_res, R_res, T_res, U_res, V_res, Ps, Ds, Pâ»Â¹s, tmp1d, tmpdd, tmpdd2, tmpKd, tmpKd2, tmpKNI, tmpKprime, s, âˆ‡W, prime_sum, prime_cut, Xáµ€prime, XXáµ€_KXXáµ€prime, K, G)
    v = mimmsvm_vars(X, X_cut, Y, W, b, E, Q, R, T, U, V, D_1s, D_2, Î›, Î£, Î©, Î˜, Îž, Î“, Î¼, YI, WmX, WyX, by, E_res, Q_res, R_res, T_res, U_res, V_res, Ps, Ds, Pâ»Â¹s, tmp1d, tmpdd, tmpdd2, tmpKd, tmpKd2, tmpKNI, tmpKprime, s, âˆ‡W, prime_sum, prime_cut, Xáµ€prime, XXáµ€_KXXáµ€prime, K, G)
end

function init_vars(model::MIMSSVMClassifier, _X, _y)
    #println("Starting init vars")
    N = length(_X) ## 416
    K = length(levels(_y)) ## 1
    G = length(model.M_cut)

    #println("sorting bags...")
    # Sort bags by class to ensure regular memory access pattern during prime indexing (see prime_cut)
    perm = sortperm(_y) 
    sort_y = _y[perm] 
    sort_X = _X[perm] 

    #println("building X...")
    X = hcat([MLJBase.matrix(x)' for x in sort_X]...) 
    @assert !any(isnan, X)
    nis = [size(x, 1) for x in sort_X] 
    X_cut = [sum(nis[1:ni])-nis[ni]+1:sum(nis[1:ni]) for ni in 1:N] 
    #println("building y cut...")
    Y = onehotbatch(sort_y, levels(sort_y)) .* 2.0 .- 1.0 

    d, NI = size(X) 
    W = randn(d, K) 
    b = randn(K) 

    #println("building introduced vars...")
    # Introduced vars
    E = randn(K, N)
    Q = randn(K, N)
    R = randn(K, N)
    T = randn(K, NI)
    U = randn(K, NI) 
    V = randn(d, K) 
    D_1s = [Matrix(1.0 * I, K, K) for g in 1:G] ## ref: https://stackoverflow.com/questions/57270276/identity-matrix-in-julia
    D_2 = Matrix(1.0 * I, d, d)
    #println("building lagrangian vars...")
    # Lagrangian Multipliers
    Î› = zeros(K, N)
    Î£ = zeros(K, N)
    Î© = zeros(K, N)
    Î˜ = zeros(K, NI)
    Îž = zeros(K, NI)
    Î“ = zeros(d, K)

    #println("calculating auxilary vars...")
    # Auxilary vars
    Î¼ = model.Î¼
    YI = hcat([repeat(Y[:,i], outer=(1, length(cut))) for (i, cut) in zip(1:N, X_cut)]...) ## 1Ã—4160 Matrix{Float64}: 1.0  1.0  1.0  1.0 ...
    WmX = randn(K, NI)
    WyX = randn(K, NI)
    by = randn(K, NI)
    E_res = zeros(size(E))
    Q_res = zeros(size(Q))
    R_res = zeros(size(R))
    T_res = zeros(size(T))
    U_res = zeros(size(U))
    V_res = zeros(size(V))

    Ps = [randn(1, 1)] 
    Ds = [Diagonal(randn(1))] 
    Pâ»Â¹s = [randn(1, 1)]

    #println("calculating auxilary vars for inexact update...")
    # Inexact vars
    s = randn(K) 
    âˆ‡W = randn(size(W)) 
    XXáµ€ = X * X' 
    prime_sum = vec(sum(YI .> 0, dims=2)) 
    prime_cut = [sum(prime_sum[1:m])-sum(prime_sum[m])+1:sum(prime_sum[1:m]) for m in 1:K]
    Xáµ€prime = [X[:,cut]' for cut in prime_cut] 
    XXáµ€_KXXáµ€prime = [XXáµ€ .+ K .* X[:,cut]*X[:,cut]' for cut in prime_cut] 

    # Temporary arrays
    tmp1d = zeros(1, d)
    tmpdd = zeros(d, d)
    tmpdd2 = zeros(d, d)
    tmpKd = zeros(K, d)
    tmpKd2 = zeros(K, d)
    tmpKNI = zeros(K, NI)
    tmpKprime = [zeros(K, size(p, 2)) for p in Xáµ€prime] 

    if CUDA.functional() && model.use_CUDA
        CUDA.allowscalar(false)
        X = convert(Array{Float64, 2}, X)

        v = mimmsvm_vars(CuArray(X), CuArray(X_cut), CuArray(Y), CuArray(W), CuArray(b), 
                       CuArray(E), CuArray(Q), CuArray(R), CuArray(T), CuArray(U), CuArray(V), D_1s,
                       CuArray(D_2), CuArray(Î›), CuArray(Î£), CuArray(Î©), CuArray(Î˜), CuArray(Îž), CuArray(Î“), Î¼, 
                       CuArray(YI), CuArray(WmX), CuArray(WyX), CuArray(by), CuArray(E_res),
                       CuArray(Q_res), CuArray(R_res), CuArray(T_res), CuArray(U_res), CuArray(V_res),
                       [CuArray(P) for P in Ps], Ds, [CuArray(P) for P in Pâ»Â¹s], CuArray(tmp1d), CuArray(tmpdd), CuArray(tmpdd2),
                       CuArray(tmpKd), CuArray(tmpKd2), CuArray(tmpKNI), [CuArray(p) for p in tmpKprime], CuArray(s), CuArray(âˆ‡W), 
                       CuArray(prime_sum), CuArray(prime_cut), [CuArray(x) for x in Xáµ€prime], [CuArray(x) for x in XXáµ€_KXXáµ€prime], K, G)
    else
        v = mimmsvm_vars(X=X, X_cut=X_cut, Y=Y, W=W, b=b, E=E, Q=Q, R=R, T=T, U=U, V=V, D_1s=D_1s, D_2=D_2, Î›=Î›, Î£=Î£, Î©=Î©, Î˜=Î˜, Îž=Îž, Î“=Î“, Î¼=Î¼, YI=YI, WmX=WmX, WyX=WyX, by=by, E_res=E_res, Q_res=Q_res, R_res=R_res, T_res=T_res, U_res=U_res, V_res=V_res, Ps=Ps, Ds=Ds, Pâ»Â¹s=Pâ»Â¹s, tmp1d=tmp1d, tmpdd=tmpdd, tmpdd2=tmpdd2, tmpKd=tmpKd, tmpKd2=tmpKd2, tmpKNI=tmpKNI, tmpKprime=tmpKprime, s=s, âˆ‡W=âˆ‡W, prime_sum=prime_sum, prime_cut=prime_cut, Xáµ€prime=Xáµ€prime, XXáµ€_KXXáµ€prime=XXáµ€_KXXáµ€prime, K=K, G=G)
    end

    # if model.exact
    #     calc_PDPs!(v)
    # end

    calc_WmX_WyX!(v)
    calc_by!(v)

    return v
end

# function g1_norm(model::MIMSSVMClassifier, v::mimmsvm_vars)
#     g1_norm = 0.0
#     for m in 1:length(model.M_cut)
#         cut = model.M_cut[m]

#         for col in 1:v.K
#             g1_norm += norm(v.V[cut, col], 2)
#         end
#     end

#     return g1_norm
# end

# function trace_norm(model::MIMSSVMClassifier, v::mimmsvm_vars)
#     return tr(sqrt.(v.W' * v.W))
# end

function p_exponent_matrix(matrix::Matrix, p::Float64 = -0.5)
    F = svd(matrix; full= false)
    # @infiltrate cond = any(isnan, F.U) || any(isnan, F.S) || any(isnan, F.Vt)
    return F.U * Diagonal(F.S.^p) * F.Vt
end

function check_nan(v::mimmsvm_vars; model = 1)
    @infiltrate cond = any(isnan, v.W)
    @infiltrate cond = any(isnan, v.b)
    @infiltrate cond = any(isnan, v.E)
    @infiltrate cond = any(isnan, v.Q)
    @infiltrate cond = any(isnan, v.R)
    @infiltrate cond = any(isnan, v.T)
    @infiltrate cond = any(isnan, v.U)
    @infiltrate cond = any(isnan, v.V)
    for g in 1:v.G
        @infiltrate cond = any(isnan, v.D_1s[g])
    end
    @infiltrate cond = any(isnan, v.Î›)
    @infiltrate cond = any(isnan, v.Î£)
    @infiltrate cond = any(isnan, v.Î©)
    @infiltrate cond = any(isnan, v.Î˜)
    @infiltrate cond = any(isnan, v.Îž)
    @infiltrate cond = any(isnan, v.Î“)
    return 0
end

function obj_loss(model::MIMSSVMClassifier, v::mimmsvm_vars)
    ð“› = 0.0
    ð“› += 0.5 * norm(v.W, 2) ^ 2.0
    ð“› += model.C * sum(max.(1 .- (bag_max!(v.Q_res, v.WmX .+ v.b, v.X_cut) .- bag_max!(v.R_res, v.WyX .+ v.by, v.X_cut)).*v.Y, 0))

    for m in 1:length(model.M_cut)
        cut = model.M_cut[m]
        for col in 1:v.K
            ð“› += model.Ï„_1 * norm(v.V[cut, col], 2)
        end
    end
    ð“› += model.Ï„_2 * tr(p_exponent_matrix(v.W' * v.W, 0.5))

    return ð“›
end

function lagrangian_loss(model::MIMSSVMClassifier, v::mimmsvm_vars; target = "all")
    ð“› = 0.0
    if target == "all"
        ð“› += 0.5 * norm(v.W, 2)^2.0
        ð“› += model.C * sum(max.(v.Y .* v.E, 0))

        for g in 1:length(model.M_cut)
            V_g = v.V[model.M_cut[g], :]
            ð“› += model.Ï„_1 * tr(V_g * v.D_1s[g] * V_g')
        end
        ð“› += model.Ï„_2 * tr((v.W)' * v.D_2 * v.W)

        ð“› += 0.5 * v.Î¼ * norm(v.E .- v.Y .+ v.Q .- v.R .+ v.Î›./v.Î¼)^2.0
        ð“› += 0.5 * v.Î¼ * norm(v.Q .- bag_max!(v.Q_res, v.T, v.X_cut) .+ v.Î£./v.Î¼)^2.0
        ð“› += 0.5 * v.Î¼ * norm(v.T .- (v.WmX .+ v.b) .+ v.Î˜./v.Î¼)^2.0
        ð“› += 0.5 * v.Î¼ * norm(v.R .- bag_max!(v.R_res, v.U, v.X_cut) .+ v.Î©./v.Î¼)^2.0
        ð“› += 0.5 * v.Î¼ * norm(v.U .- (v.WyX .+ v.by) .+ v.Îž./v.Î¼)^2.0
        ð“› += 0.5 * v.Î¼ * norm(v.V .- v.W .+ v.Î“ ./ v.Î¼)^2.0
    elseif target == "V"
        for g in 1:length(model.M_cut)
            V_g = v.V[model.M_cut[g], :]
            ð“› += model.Ï„_1 * tr(V_g * v.D_1s[g] * V_g')
        end
        ð“› += 0.5 * v.Î¼ * norm(v.V .- v.W .+ v.Î“ ./ v.Î¼)^2.0
    elseif target == "T"
        ð“› += 0.5 * v.Î¼ * norm(v.Q .- bag_max!(v.Q_res, v.T, v.X_cut) .+ v.Î£./v.Î¼)^2.0
        ð“› += 0.5 * v.Î¼ * norm(v.T .- (v.WmX .+ v.b) .+ v.Î˜./v.Î¼)^2.0
    end        
    return ð“›
end

function inexact_loss(model::MIMSSVMClassifier, v::mimmsvm_vars)
    d = size(v.W, 1)
    s = repeat(v.s', outer=(d, 1))

    newW = v.W - s.*v.âˆ‡W
    newWX = newW' * v.X
    K = size(v.Y, 1)
    newWyX = repeat(newWX[v.YI .> 0]', outer=(K, 1))

    ð“› = 0.0
    ð“› += 0.5 * norm(newW, 2)^2.0
    ð“› += model.Ï„_2 * tr(newW' * v.D_2 * newW)
    ð“› += 0.5 * v.Î¼ * norm(v.V .- newW .+ v.Î“ ./ v.Î¼)^2.0
    ð“› += 0.5 * v.Î¼ * norm(v.T .- (newWX .+ v.b) .+ v.Î˜/v.Î¼)^2.0
    ð“› += 0.5 * v.Î¼ * norm(v.U .- (newWyX + v.by) .+ v.Îž/v.Î¼)^2.0
end

function bag_max(WX, X_cut)
    return hcat([maximum(WX[:, cut], dims=2) for cut in X_cut]...)
end

function bag_max!(R, WX, X_cut)
    ## R = 1Ã—416 Matrix{Float64}, 
    for (i, cut) in enumerate(X_cut)
        c = @view WX[:, cut] 
        r = @view R[:,i]
        maximum!(r, c)
    end
    return R
end

# function calc_precomputed_vars(v::mimmsvm_vars)
#     d, K = size(v.W)
# end

function calc_PDPs!(v::mimmsvm_vars)
    ## Not works in MMMISVM
    d, K = size(v.W)

    rhs1 = sum([v.X[:,cut]*v.X[:,cut]' for cut in v.X_cut]) 
    rhs2 = [zeros(d, d) for i in 1:K] 
    for m in 1:K
        step1 = [v.X[:,cut][:,v.YI[:,cut][m,:] .> 0] for cut in v.X_cut]
        rhs2[m] = sum([x * x' for x in step1])
    end
    As = [rhs1 + K*r2 for r2 in rhs2] 
    eigAs = [eigen(A) for A in As] 

    v.Ps = [real(eigA.vectors) for eigA in eigAs] 
    v.Ds = [Diagonal(real(eigA.values)) for eigA in eigAs] 
    v.Pâ»Â¹s = [real(inv(eigA.vectors)) for eigA in eigAs] 

    v.Xáµ€prime = [v.X[:,cut]' for cut in v.prime_cut] 
end

function calc_WmX_WyX!(v::mimmsvm_vars)
    mul!(v.WmX, v.W', v.X) 
    K = size(v.Y, 1) 
    v.tmpKNI .= v.WmX .* (v.YI .> 0) 
    for m in 1:K
        tmp = @view v.WyX[m:m,:] 
        sum!(tmp, v.tmpKNI)
    end
end

function calc_by!(v::mimmsvm_vars)
    for m in 1:size(v.Y, 1)
        bym = @view v.by[:, v.prime_cut[m]] 
        bym .= v.b[m] 
    end
end

function W_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    ## refer: https://math.stackexchange.com/questions/670649/efficient-diagonal-update-of-matrix-inverse
    K, NI = size(v.T)
    d = size(v.W, 1)

    @. v.T_res = v.T - v.b + v.Î˜/v.Î¼; TÌ‚ = @view v.T_res[:,:] 
    ## "@." converts all the operations of that line into element-wise: https://stackoverflow.com/questions/65160733/what-does-an-at-sign-mean-in-julia
    @. v.U_res = v.U - v.by + v.Îž/v.Î¼; UÌ‚ = @view v.U_res[:,:] 
    mul!(v.tmpKd, TÌ‚, v.X') 

    d, K = size(v.W)
    rhs1 = sum([v.X[:,cut]*v.X[:,cut]' for cut in v.X_cut]) 

    for m in 1:K
        UÌ‚prime = @view UÌ‚[:,v.prime_cut[m]]; tÌ‚Xáµ€ = @view v.tmpKd[m,:]; w = @view v.W[:,m:m]

        mul!(v.tmpKd2, UÌ‚prime, v.Xáµ€prime[m]) 

        sum!(v.tmp1d, v.tmpKd2) 
        @. v.tmp1d += tÌ‚Xáµ€' + (v.V[:, m])' + (v.Î“[:, m])' ./ v.Î¼ 

        step1 = [v.X[:,cut][:,v.YI[:,cut][m,:] .> 0] for cut in v.X_cut]
        rhs2 = sum([x * x' for x in step1]) 

        As = rhs1 + K * rhs2 
        As += (2 / v.Î¼) * model.Ï„_2 * v.D_2 + (1.0 / v.Î¼ + 1) * I
        
        v.W[:,m] = v.tmp1d * inv(As)
    end

    calc_WmX_WyX!(v)
end

function inexact_W_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    s_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    d = size(v.W, 1)

    @. v.W -= v.âˆ‡W .* v.s'

    calc_WmX_WyX!(v)
end

function s_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    K, NI = size(v.T)

    v.T_res .= v.T .- v.WmX .- v.b .+ v.Î˜./v.Î¼; TÌ‚ = @view v.T_res[:,:]
    v.U_res .= v.U .- v.WyX .- v.by .+ v.Îž./v.Î¼; UÌ‚ = @view v.U_res[:,:]
    mul!(v.tmpKd, TÌ‚,  v.X')
    v.tmpKd .= v.W' .- v.Î¼ .* v.tmpKd 

    for m in 1:K
        UÌ‚prime = @view UÌ‚[:,v.prime_cut[m]] 
        tmp1d = @view v.tmpKd[m,:] 
        w = @view v.W[:,m]
        mul!(v.tmpKprime[m], UÌ‚prime, v.Xáµ€prime[m]) 
        UÌ‚Xáµ€prime = @view v.tmpKprime[m][:,:]

        âˆ‡w = @view v.âˆ‡W[:,m] 
        sum!(âˆ‡w, UÌ‚Xáµ€prime')

        âˆ‡w .= tmp1d .- v.Î¼ .* âˆ‡w 
        âˆ‡w += (- v.Î¼ * (v.V[:, m] - w + v.Î“[:, m] / v.Î¼) + model.Ï„_2 * v.D_2 * w) 

        Xáµ€âˆ‡w = @view v.tmpKNI[m,:]; mul!(Xáµ€âˆ‡w, v.X', âˆ‡w); tÌ‚ = @view TÌ‚[m,:]
        numer = w' * âˆ‡w .- v.Î¼ * (tÌ‚' * Xáµ€âˆ‡w) .- v.Î¼ * sum(UÌ‚Xáµ€prime * âˆ‡w, dims=1) 
        numer[1] += (w' * (2 * model.Ï„_2 .* v.D_2) - v.Î¼ * (v.V[:, m] - w + v.Î“[:, m] ./ v.Î¼)') * âˆ‡w 
        mul!(tmp1d, v.XXáµ€_KXXáµ€prime[m], âˆ‡w)
        denom = âˆ‡w' * âˆ‡w .+ v.Î¼ .* âˆ‡w' * tmp1d
        denom[1] +=  âˆ‡w' * (v.Î¼ * I + 2 * model.Ï„_2 * v.D_2) * âˆ‡w
        v.s[m] = numer[1] / denom[1]
    end
end

function D_1s_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    G = length(model.M_cut)
    for g in 1:G
        v_g = v.V[model.M_cut[g], :]
        for k in 1:v.K
            v.D_1s[g][k, k] = 0.5 * sqrt(norm(v_g[:, k], 2)^2 + model.Î´)
        end
    end
end

function D_2_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    # @infiltrate cond = any(isnan, v.W)
    v.D_2 = 0.5 * p_exponent_matrix(v.W * v.W' + model.Î´ * I, -0.5)
end

function b_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    K, NI = size(v.YI)

    @. v.T_res = v.T - v.WmX + v.Î˜/v.Î¼; TÌ‚ = @view v.T_res[:,:]
    @. v.U_res = v.U - v.WyX + v.Îž/v.Î¼; UÌ‚ = @view v.U_res[:,:]
    sum!(v.b, TÌ‚)
    for m in 1:K
        UÌ‚prime = @view UÌ‚[:,v.prime_cut[m]]
        v.b[m] += sum(UÌ‚prime)
    end
    v.b .= v.b ./ (NI .+ K .* v.prime_sum)

    calc_by!(v)
end

function E_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    S = @view v.E_res[:,:]; S .= v.Y .- v.Q .+ v.R .- v.Î›./v.Î¼
    YS = @view v.Q_res[:,:]; YS .= v.Y .* S
    gt = YS .> model.C/v.Î¼
    mid = 0 .<= YS .<= model.C/v.Î¼

    v.E .= S .* .!mid .- gt .* v.Y .* (model.C/v.Î¼)
end

function Q_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    bag_max!(v.Q_res, v.T, v.X_cut); bag_max_T = @view v.Q_res[:,:]
    v.Q .= 0.5 .* (v.Y .- v.E .+ v.R .- v.Î›./v.Î¼ .+ bag_max_T .- v.Î£./v.Î¼)
end

function R_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    bag_max!(v.R_res, v.U, v.X_cut); bag_max_U = @view v.R_res[:,:]
    v.R .= 0.5 .* (v.E .- v.Y .+ v.Q .+ v.Î›./v.Î¼ .+ bag_max_U .- v.Î©./v.Î¼)
end

function T_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    K = size(v.Y, 1)
    v.T_res .= v.WmX .+ v.b .- v.Î˜./v.Î¼ # Store data in T_res to save allocations
    Î¦ = @view v.T_res[:,:]
    for (i, cut) in enumerate(v.X_cut)
        ni = length(cut)
        for m in 1:K
            Ï•áµ¢â‚˜ = @view Î¦[m, cut]
            v.T[m,cut] = Ï•áµ¢â‚˜
            v.T[m,cut[1]+argmax(Ï•áµ¢â‚˜)-1] = 0.5 * (maximum(Ï•áµ¢â‚˜) + v.Q[m, i] + v.Î£[m, i]/v.Î¼)
        end
    end
    """
    for (i, cut) in enumerate(v.X_cut)
        ni = length(cut)
        for m in 1:K
            Ï•áµ¢â‚˜_prime = sort(Ï•áµ¢â‚˜, rev=true)
            a_imc = [(sum(Ï•áµ¢â‚˜_prime[1:j]) + qáµ¢[m] + Ïƒáµ¢[m]/v.Î¼) / (j + 1) for j in 1:ni]
            #println(a_imc .> Ï•áµ¢â‚˜_prime)
            c_star = argmax(a_imc .> Ï•áµ¢â‚˜_prime) - 1
            #println(c_star)
            if c_star > 0
                a_imcstar = a_imc[c_star]
                v.T[m,cut] = min.(Ï•áµ¢â‚˜, a_imcstar)
            else
                v.T[m,cut] = Ï•áµ¢â‚˜
                v.T[m,cut[1]+argmax(Ï•áµ¢â‚˜)-1]=a_imc[1]
            end
        end
    end
    """
end

function U_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    K = size(v.Y, 1)
    v.U_res .= v.WyX .+ v.by .- v.Îž./v.Î¼ # Store data in U_res to save allocations
    Î¨ = @view v.U_res[:,:]
    for (i, cut) in enumerate(v.X_cut)
        ni = length(cut)
        for m in 1:K
            Ïˆáµ¢â‚˜ = @view Î¨[m, cut]
            v.U[m,cut] = Ïˆáµ¢â‚˜
            v.U[m,cut[1]+argmax(Ïˆáµ¢â‚˜)-1] = 0.5 * (maximum(Ïˆáµ¢â‚˜) + v.R[m, i] + v.Î©[m, i]/v.Î¼)
        end
    end
    """
    for (i, cut) in enumerate(v.X_cut)
        ni = length(cut)
        for m in 1:K
            Ïˆáµ¢â‚˜_prime = sort(Ïˆáµ¢â‚˜, rev=true)
            a_imc = [(sum(Ïˆáµ¢â‚˜_prime[1:j]) + v.R[m,i] + v.Î©[m,i]/v.Î¼) / (j + 1) for j in 1:ni]
            #println(a_imc .> Ïˆáµ¢â‚˜_prime)
            c_star = argmax(a_imc .> Ïˆáµ¢â‚˜_prime)-1
            #println(c_star)
            if c_star > 1
                a_imcstar = a_imc[c_star]
                v.U[m,cut] = min.(Ïˆáµ¢â‚˜, a_imcstar)
            else
                v.U[m,cut] = Ïˆáµ¢â‚˜
                v.U[m,cut[1]+argmax(Ïˆáµ¢â‚˜)-1] = a_imc[1]
            end
        end
    end
    """
end

function V_update!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    G = length(model.M_cut)
    for g in 1:G
        right_parenthis = (2 * model.Ï„_1 .* v.D_1s[g] + v.Î¼ .* I)
        diagindices = diagind(right_parenthis)
        right_parenthis[diagindices] = 1.0 ./ right_parenthis[diagindices] ## more efficient than matrix inversion.
        v.V[model.M_cut[g], :] = (v.Î¼ .* v.W[model.M_cut[g], :] - v.Î“[model.M_cut[g], :]) * right_parenthis
    end
end

function calc_residuals!(model::MIMSSVMClassifier, v::mimmsvm_vars)
    v.E_res .= v.E .- (v.Y .- v.Q .+ v.R)
    v.Q_res .= v.Q .- bag_max!(v.Q_res, v.T, v.X_cut)
    v.T_res .= v.T .- (v.WmX .+ v.b)
    v.R_res .= v.R .- bag_max!(v.R_res, v.U, v.X_cut)
    v.U_res .= v.U .- (v.WyX .+ v.by)
end

function MIMSSVMClassifier(; M_cut=missing, Î´=1e-10, Ï„_1=1.0, Ï„_2=1.0, C=1.0, Î¼=1e-3, Ï=1.2, maxiter=1000, tol=1e-6, use_CUDA=false, exact=true)
    @assert all(i -> (i > 0), [C, Î¼, Ï, maxiter, tol])
    @assert Ï > 1.0
    model = MIMSSVMClassifier(M_cut, Î´, Ï„_1, Ï„_2, C, Î¼, Ï, maxiter, tol, use_CUDA, exact)
end

function MLJBase.fit(model::MIMSSVMClassifier, verbosity::Integer, X, y)
    v = init_vars(model, X, y)

    @assert !any(isnan, v.X)
    if verbosity > 5
        calc_residuals!(model, v)
        res = sum([norm(r) for r in (v.E_res, v.Q_res, v.T_res, v.R_res, v.U_res)])

        ol = obj_loss(model, v)
        ll = lagrangian_loss(model, v)
        print("Loss: " * string(ol) * "     \t") 
        print("Lagrangian: " * string(ll) * "     \t") 
        println("Residual: " * string(res))
    end

    #reset_timer!()
    for i in 1:model.maxiter
        D_1s_update!(model, v)
        D_2_update!(model, v)
        if model.exact
            W_update!(model, v)
        else
            inexact_W_update!(model, v)
        end
        b_update!(model, v)
        E_update!(model, v)
        Q_update!(model, v)
        R_update!(model, v)
        T_update!(model, v)
        U_update!(model, v)
        V_update!(model, v)

        calc_residuals!(model, v)

        @. v.Î› += v.Î¼ * v.E_res
        @. v.Î£ += v.Î¼ * v.Q_res
        @. v.Î˜ += v.Î¼ * v.T_res 
        @. v.Î© += v.Î¼ * v.R_res
        @. v.Îž += v.Î¼ * v.U_res
        @. v.Î“ += v.Î¼ * v.V_res
         
        res = sum([norm(r) for r in (v.E_res, v.Q_res, v.T_res, v.R_res, v.U_res, v.V_res)])

        if verbosity > 5
            ol = obj_loss(model, v)
            ll = lagrangian_loss(model, v)
            print("Loss: " * string(ol) * "     \t")
            print("Lagrangian: " * string(ll) * "     \t")
            println("Residual: " * string(res))
        end

        if res < model.tol
            break
        end

        v.Î¼ = model.Ï * v.Î¼
    end

    #if verbosity > 5
    #    print_timer()
    #end

    fitresult = v.W, v.b, levels(y)
    cache = missing
    report = missing

    return fitresult, cache, report
end

function MLJBase.predict(model::MIMSSVMClassifier, fitresult, Xnew)
    N = length(Xnew)
    W, b, levels_of_y = fitresult

    X = hcat([MLJBase.matrix(x)' for x in Xnew]...)
    nis = [size(x, 1) for x in Xnew]
    X_cut = [sum(nis[1:ni])-nis[ni]+1:sum(nis[1:ni]) for ni in 1:N]
    raw_pred = bag_max(W' * X .+ b, X_cut)

    pred = CategoricalArray(onecold(raw_pred, levels_of_y))

    return pred
end
